# NLP Projects

This folder contains various projects focused on different NLP techniques. Below is a brief overview of each project:

## 1. Transformer - nano-gpt
Applied a transformer architecture to create a character-based text generator. The model was trained on Shakespeare's texts.

## 2. RNN Part-of-Speech Tagging
Implemented an LSTM recurrent neural network architecture to learn the parts of speech for each word in a text.

## 3. Disaster Tweets
A Kaggle competition aimed at predicting whether tweets were about disasters. The main technique used was fine-tuning a BERT model with a neural network. The performance of this model was compared to traditional NLP models.

## 4. Cipher Decrypt
Utilized a Markov transition model to discover the character mapping used in the encryption of a message. Through a genetic algorithm, the mapping that maximized the likelihood of the decrypted message was sought.

## 5. Spam Detector
Employed TF-IDF and Naive Bayes for spam detection. Additionally, the model was compared using Latent Semantic Analysis for dimensionality reduction.

## 6. Sentiment Analysis
Utilized logistic regression to classify the sentiment of tweets related to an airline company.

## 7. TextRank Summarization
Applied the PageRank technique to rank key topics. This involved calculating the Markov matrix and finding eigenvectors to rank the most important sentences (highest eigenvalues).

## 8. Recommendation Movie System
Used the nearest neighbors algorithm to recommend movies based on their descriptions.

