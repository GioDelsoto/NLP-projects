{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "581e2bb1",
   "metadata": {
    "papermill": {
     "duration": 0.012096,
     "end_time": "2024-07-15T18:04:58.243101",
     "exception": false,
     "start_time": "2024-07-15T18:04:58.231005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Text Summarization\n",
    "\n",
    "### There are two types of text summarization:\n",
    "1. **Extractive summaries:** These summaries remove parts of the text that are less important, keeping the most significant parts intact (easier to implement).\n",
    "2. **Abstractive summaries:** These summaries create new sentences using words that may not be present in the original text.\n",
    "\n",
    "### We will use the extractive approach, and to achieve this goal, we will follow these steps:\n",
    "\n",
    "1. Break the document into sentences (using `nltk.sent_tokenize()`).\n",
    "2. Treat each sentence as a document.\n",
    "3. Compute the Tf-Idf matrix.\n",
    "4. Compute the score for each sentence (**).\n",
    "5. Sort the sentences in descending order based on their scores.\n",
    "\n",
    "### (**) How to Compute the Sentence Score\n",
    "\n",
    "We will use a scoring method similar to Google's PageRank, which is based on a random walk. After an infinite number of walks, our state distribution will converge to a limit distribution. The \"walks\" follow a Markov Matrix distribution. For web pages, Google uses hyperlinks to move to the next page. For our purpose, we will calculate the cosine similarity for each sentence, and these values will be used as probabilities (after normalization).\n",
    "\n",
    "Here's the key idea:\n",
    "\n",
    "The probability of changing the state at time ( t ) is:\n",
    "\n",
    "p(s_{t+1}) = p(s_t) * p(s_{t+1} | s_t) = p(s_t) * A_{(t+1,t)} \n",
    "\n",
    "where A is the Markov Matrix.\n",
    "\n",
    "As t approaches infinity (t -> \\infty):\n",
    "\n",
    "p(s_{\\infty}) = p(s_{\\infty}) x A_{(t+1, t)}\n",
    "\n",
    "This follows the eigenvectors of a matrix (\\lambda.v = A.v), with \\lambda being the eigenvalue and v being the eigenvector).\n",
    "\n",
    "So, we need to compute the Markov Matrix and find the eigenvector associated with an eigenvalue of 1. This eigenvector will represent the limiting state distribution, and its values will be the scores for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8666d34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-15T18:04:58.269391Z",
     "iopub.status.busy": "2024-07-15T18:04:58.268932Z",
     "iopub.status.idle": "2024-07-15T18:05:02.051995Z",
     "shell.execute_reply": "2024-07-15T18:05:02.050505Z"
    },
    "papermill": {
     "duration": 3.801995,
     "end_time": "2024-07-15T18:05:02.057378",
     "exception": false,
     "start_time": "2024-07-15T18:04:58.255383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /kaggle/working/...\n",
      "Archive:  /kaggle/working/corpora/wordnet.zip\n",
      "   creating: /kaggle/working/corpora/wordnet/\n",
      "  inflating: /kaggle/working/corpora/wordnet/lexnames  \n",
      "  inflating: /kaggle/working/corpora/wordnet/data.verb  \n",
      "  inflating: /kaggle/working/corpora/wordnet/index.adv  \n",
      "  inflating: /kaggle/working/corpora/wordnet/adv.exc  \n",
      "  inflating: /kaggle/working/corpora/wordnet/index.verb  \n",
      "  inflating: /kaggle/working/corpora/wordnet/cntlist.rev  \n",
      "  inflating: /kaggle/working/corpora/wordnet/data.adj  \n",
      "  inflating: /kaggle/working/corpora/wordnet/index.adj  \n",
      "  inflating: /kaggle/working/corpora/wordnet/LICENSE  \n",
      "  inflating: /kaggle/working/corpora/wordnet/citation.bib  \n",
      "  inflating: /kaggle/working/corpora/wordnet/noun.exc  \n",
      "  inflating: /kaggle/working/corpora/wordnet/verb.exc  \n",
      "  inflating: /kaggle/working/corpora/wordnet/README  \n",
      "  inflating: /kaggle/working/corpora/wordnet/index.sense  \n",
      "  inflating: /kaggle/working/corpora/wordnet/data.noun  \n",
      "  inflating: /kaggle/working/corpora/wordnet/data.adv  \n",
      "  inflating: /kaggle/working/corpora/wordnet/index.noun  \n",
      "  inflating: /kaggle/working/corpora/wordnet/adj.exc  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Download and unzip wordnet\n",
    "try:\n",
    "    nltk.data.find('wordnet.zip')\n",
    "except:\n",
    "    nltk.download('wordnet', download_dir='/kaggle/working/')\n",
    "    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n",
    "    subprocess.run(command.split())\n",
    "    nltk.data.path.append('/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d73a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.104526Z",
     "iopub.status.busy": "2024-07-15T18:05:02.103928Z",
     "iopub.status.idle": "2024-07-15T18:05:02.262165Z",
     "shell.execute_reply": "2024-07-15T18:05:02.260952Z"
    },
    "papermill": {
     "duration": 0.177824,
     "end_time": "2024-07-15T18:05:02.265008",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.087184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir = '../input/bbc-dataset/'\n",
    "\n",
    "df = pd.read_csv(dir+'bbc_text_cls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb66eb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.290508Z",
     "iopub.status.busy": "2024-07-15T18:05:02.290052Z",
     "iopub.status.idle": "2024-07-15T18:05:02.321294Z",
     "shell.execute_reply": "2024-07-15T18:05:02.320305Z"
    },
    "papermill": {
     "duration": 0.047126,
     "end_time": "2024-07-15T18:05:02.324011",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.276885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ddf7d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.355250Z",
     "iopub.status.busy": "2024-07-15T18:05:02.354784Z",
     "iopub.status.idle": "2024-07-15T18:05:02.369893Z",
     "shell.execute_reply": "2024-07-15T18:05:02.368634Z"
    },
    "papermill": {
     "duration": 0.032297,
     "end_time": "2024-07-15T18:05:02.372848",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.340551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = df[df.labels=='business']['text'].sample(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7721274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.398929Z",
     "iopub.status.busy": "2024-07-15T18:05:02.398535Z",
     "iopub.status.idle": "2024-07-15T18:05:02.407506Z",
     "shell.execute_reply": "2024-07-15T18:05:02.406187Z"
    },
    "papermill": {
     "duration": 0.024846,
     "end_time": "2024-07-15T18:05:02.409977",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.385131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480    Christmas sales worst since 1981\\n\\nUK retail ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bb3ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.437123Z",
     "iopub.status.busy": "2024-07-15T18:05:02.436734Z",
     "iopub.status.idle": "2024-07-15T18:05:02.442253Z",
     "shell.execute_reply": "2024-07-15T18:05:02.441074Z"
    },
    "papermill": {
     "duration": 0.021555,
     "end_time": "2024-07-15T18:05:02.444638",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.423083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Removing the title\n",
    "\n",
    "corpus = corpus.iloc[0].split(\"\\n\",1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd402dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.470875Z",
     "iopub.status.busy": "2024-07-15T18:05:02.470457Z",
     "iopub.status.idle": "2024-07-15T18:05:02.477639Z",
     "shell.execute_reply": "2024-07-15T18:05:02.476566Z"
    },
    "papermill": {
     "duration": 0.023184,
     "end_time": "2024-07-15T18:05:02.480107",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.456923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUK retail sales fell in December, failing to meet expectations and making it by some counts the worst Christmas since 1981.\\n\\nRetail sales dropped by 1% on the month in December, after a 0.6% rise in November, the Office for National Statistics (ONS) said. The ONS revised the annual 2004 rate of growth down from the 5.9% estimated in November to 3.2%. A number of retailers have already reported poor figures for December. Clothing retailers and non-specialist stores were the worst hit with only internet retailers showing any significant growth, according to the ONS.\\n\\nThe last time retailers endured a tougher Christmas was 23 years previously, when sales plunged 1.7%.\\n\\nThe ONS echoed an earlier caution from Bank of England governor Mervyn King not to read too much into the poor December figures. Some analysts put a positive gloss on the figures, pointing out that the non-seasonally-adjusted figures showed a performance comparable with 2003. The November-December jump last year was roughly comparable with recent averages, although some way below the serious booms seen in the 1990s. And figures for retail volume outperformed measures of actual spending, an indication that consumers are looking for bargains, and retailers are cutting their prices.\\n\\nHowever, reports from some High Street retailers highlight the weakness of the sector. Morrisons, Woolworths, House of Fraser, Marks & Spencer and Big Food all said that the festive period was disappointing.\\n\\nAnd a British Retail Consortium survey found that Christmas 2004 was the worst for 10 years. Yet, other retailers - including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that festive sales were well up on last year. Investec chief economist Philip Shaw said he did not expect the poor retail figures to have any immediate effect on interest rates. \"The retail sales figures are very weak, but as Bank of England governor Mervyn King indicated last night, you don\\'t really get an accurate impression of Christmas trading until about Easter,\" said Mr Shaw. \"Our view is the Bank of England will keep its powder dry and wait to see the big picture.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce0f7f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.507036Z",
     "iopub.status.busy": "2024-07-15T18:05:02.506564Z",
     "iopub.status.idle": "2024-07-15T18:05:02.526848Z",
     "shell.execute_reply": "2024-07-15T18:05:02.525685Z"
    },
    "papermill": {
     "duration": 0.037362,
     "end_time": "2024-07-15T18:05:02.529983",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.492621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = nltk.sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc7db63e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:02.559123Z",
     "iopub.status.busy": "2024-07-15T18:05:02.558031Z",
     "iopub.status.idle": "2024-07-15T18:05:05.169649Z",
     "shell.execute_reply": "2024-07-15T18:05:05.168450Z"
    },
    "papermill": {
     "duration": 2.62911,
     "end_time": "2024-07-15T18:05:05.172546",
     "exception": false,
     "start_time": "2024-07-15T18:05:02.543436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Lemmatizing the input\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Função de lematização\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "docs_lemma = [lemmatize_text(doc) for doc in docs]\n",
    "len(docs_lemma)\n",
    "\n",
    "docs_lemma = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "931f094f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.200248Z",
     "iopub.status.busy": "2024-07-15T18:05:05.199823Z",
     "iopub.status.idle": "2024-07-15T18:05:05.224088Z",
     "shell.execute_reply": "2024-07-15T18:05:05.222611Z"
    },
    "papermill": {
     "duration": 0.041304,
     "end_time": "2024-07-15T18:05:05.227034",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.185730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compute Tf-Idf Matrix\n",
    "tf_docs = TfidfVectorizer(decode_error='ignore', stop_words = 'english', norm = 'l1').fit_transform(docs_lemma)\n",
    "N, V = tf_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e783c",
   "metadata": {
    "papermill": {
     "duration": 0.013693,
     "end_time": "2024-07-15T18:05:05.253334",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.239641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Computing the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1716cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.280971Z",
     "iopub.status.busy": "2024-07-15T18:05:05.280493Z",
     "iopub.status.idle": "2024-07-15T18:05:05.288104Z",
     "shell.execute_reply": "2024-07-15T18:05:05.286589Z"
    },
    "papermill": {
     "duration": 0.024581,
     "end_time": "2024-07-15T18:05:05.291095",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.266514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(row1, row2):\n",
    "    \n",
    "    dot_product = row1.dot(row2.T).toarray()[0, 0]\n",
    "    norm1 = np.sqrt(row1.multiply(row1).sum())\n",
    "    norm2 = np.sqrt(row2.multiply(row2).sum())\n",
    "    \n",
    "    cos_similarity = dot_product/(norm1*norm2)\n",
    "    return cos_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc901fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.318123Z",
     "iopub.status.busy": "2024-07-15T18:05:05.317674Z",
     "iopub.status.idle": "2024-07-15T18:05:05.665130Z",
     "shell.execute_reply": "2024-07-15T18:05:05.663787Z"
    },
    "papermill": {
     "duration": 0.364413,
     "end_time": "2024-07-15T18:05:05.668045",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.303632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Computing the Markov-Matrix - M x M -> M = number of sentences\n",
    "markov_matrix = np.zeros((N,N))\n",
    "for i in range(N):\n",
    "    \n",
    "    for j in range(N):\n",
    "        \n",
    "        markov_matrix[i,j] = cosine_similarity(tf_docs[i,:], tf_docs[j,:])\n",
    "    \n",
    "    #Normalize the row:\n",
    "    markov_matrix[i,:] = markov_matrix[i,:]/(markov_matrix[i,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a53264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.694765Z",
     "iopub.status.busy": "2024-07-15T18:05:05.694323Z",
     "iopub.status.idle": "2024-07-15T18:05:05.702579Z",
     "shell.execute_reply": "2024-07-15T18:05:05.701250Z"
    },
    "papermill": {
     "duration": 0.024699,
     "end_time": "2024-07-15T18:05:05.705165",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.680466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07039704, 0.49092893, 0.09514263, 0.03284654, 0.02693908,\n",
       "       0.02951514, 0.04657406, 0.        , 0.07303445, 0.02222435,\n",
       "       0.        , 0.0397964 , 0.02708133, 0.02693285, 0.05023479,\n",
       "       0.05000916, 0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markov_matrix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bdbd5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.733181Z",
     "iopub.status.busy": "2024-07-15T18:05:05.732747Z",
     "iopub.status.idle": "2024-07-15T18:05:05.739591Z",
     "shell.execute_reply": "2024-07-15T18:05:05.738195Z"
    },
    "papermill": {
     "duration": 0.024318,
     "end_time": "2024-07-15T18:05:05.742594",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.718276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Smoothing the matrix\n",
    "lambda_smooth = 0.15\n",
    "U = np.ones((N,N))*1/N\n",
    "\n",
    "markov_matrix = markov_matrix*(1-lambda_smooth) + lambda_smooth*U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "296c3d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.769995Z",
     "iopub.status.busy": "2024-07-15T18:05:05.769534Z",
     "iopub.status.idle": "2024-07-15T18:05:05.776991Z",
     "shell.execute_reply": "2024-07-15T18:05:05.775799Z"
    },
    "papermill": {
     "duration": 0.024412,
     "end_time": "2024-07-15T18:05:05.779820",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.755408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1094237467877974e-15\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Ensuring that is still normalized\n",
    "print((markov_matrix.sum(axis = 0) - 1).sum())\n",
    "\n",
    "#Ensuring that all values > 0\n",
    "print((markov_matrix[markov_matrix<=0].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e52e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.807323Z",
     "iopub.status.busy": "2024-07-15T18:05:05.806888Z",
     "iopub.status.idle": "2024-07-15T18:05:05.826531Z",
     "shell.execute_reply": "2024-07-15T18:05:05.825254Z"
    },
    "papermill": {
     "duration": 0.036582,
     "end_time": "2024-07-15T18:05:05.829559",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.792977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Computing eigenvector of markov_matrix\n",
    "\n",
    "# In linear algebra: A * x = lambda * x; x = columns vector.  -> But we have rows: rows * A = rows * lambda; so we need to transpose A to have the same format\n",
    "eigenvalues, eigenvectors = np.linalg.eig(markov_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2861d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.857322Z",
     "iopub.status.busy": "2024-07-15T18:05:05.856378Z",
     "iopub.status.idle": "2024-07-15T18:05:05.863054Z",
     "shell.execute_reply": "2024-07-15T18:05:05.861786Z"
    },
    "papermill": {
     "duration": 0.023752,
     "end_time": "2024-07-15T18:05:05.866143",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.842391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.21864025 0.71410912 0.31883039 0.33623722 0.66557628\n",
      " 0.37708749 0.40113565 0.40980739 0.42617867 0.63084392 0.61855497\n",
      " 0.59979725 0.55533    0.48662142 0.5061532  0.52044964]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38d8ef5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.896781Z",
     "iopub.status.busy": "2024-07-15T18:05:05.896343Z",
     "iopub.status.idle": "2024-07-15T18:05:05.902656Z",
     "shell.execute_reply": "2024-07-15T18:05:05.901431Z"
    },
    "papermill": {
     "duration": 0.024401,
     "end_time": "2024-07-15T18:05:05.905452",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.881051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the index where eigenvalue = 1\n",
    "def find_eigenvectors(eigvalues, value):\n",
    "    distance = np.abs(eigvalues-value)\n",
    "    idx_min = distance.argmin()\n",
    "    \n",
    "    return idx_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff2bfcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.932802Z",
     "iopub.status.busy": "2024-07-15T18:05:05.932350Z",
     "iopub.status.idle": "2024-07-15T18:05:05.938833Z",
     "shell.execute_reply": "2024-07-15T18:05:05.937559Z"
    },
    "papermill": {
     "duration": 0.023266,
     "end_time": "2024-07-15T18:05:05.941672",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.918406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = find_eigenvectors(eigenvalues, 1)\n",
    "p_inf = eigenvectors[:,idx]  #Limit distribution\n",
    "\n",
    "sentence_score = p_inf/p_inf.sum() #Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48fb9ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:05.969431Z",
     "iopub.status.busy": "2024-07-15T18:05:05.968976Z",
     "iopub.status.idle": "2024-07-15T18:05:05.976722Z",
     "shell.execute_reply": "2024-07-15T18:05:05.975577Z"
    },
    "papermill": {
     "duration": 0.024474,
     "end_time": "2024-07-15T18:05:05.979267",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.954793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06008621, 0.06624912, 0.05383286, 0.07433314, 0.06127197,\n",
       "       0.05818043, 0.07018035, 0.05266862, 0.05273009, 0.0553683 ,\n",
       "       0.05009977, 0.05087408, 0.05821364, 0.05805022, 0.05754962,\n",
       "       0.06936807, 0.0509435 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25f4353b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:06.007846Z",
     "iopub.status.busy": "2024-07-15T18:05:06.007441Z",
     "iopub.status.idle": "2024-07-15T18:05:06.015567Z",
     "shell.execute_reply": "2024-07-15T18:05:06.014170Z"
    },
    "papermill": {
     "duration": 0.025763,
     "end_time": "2024-07-15T18:05:06.018141",
     "exception": false,
     "start_time": "2024-07-15T18:05:05.992378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_score.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66a244ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:06.046970Z",
     "iopub.status.busy": "2024-07-15T18:05:06.046517Z",
     "iopub.status.idle": "2024-07-15T18:05:06.053155Z",
     "shell.execute_reply": "2024-07-15T18:05:06.051890Z"
    },
    "papermill": {
     "duration": 0.024422,
     "end_time": "2024-07-15T18:05:06.055703",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.031281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "idx_sort = np.argsort(-sentence_score)\n",
    "\n",
    "top_n_sentences = [docs_lemma[idx] for idx in idx_sort[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df69c74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:06.083961Z",
     "iopub.status.busy": "2024-07-15T18:05:06.083549Z",
     "iopub.status.idle": "2024-07-15T18:05:06.091585Z",
     "shell.execute_reply": "2024-07-15T18:05:06.090113Z"
    },
    "papermill": {
     "duration": 0.025138,
     "end_time": "2024-07-15T18:05:06.094124",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.068986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Summary:\n",
      "\n",
      "[7.43%] A number of retailers have already reported poor figures for December.\n",
      "\n",
      "[7.02%] The ONS echoed an earlier caution from Bank of England governor Mervyn King not to read too much into the poor December figures.\n",
      "\n",
      "[6.94%] \"The retail sales figures are very weak, but as Bank of England governor Mervyn King indicated last night, you don't really get an accurate impression of Christmas trading until about Easter,\" said Mr Shaw.\n",
      "\n",
      "[6.62%] Retail sales dropped by 1% on the month in December, after a 0.6% rise in November, the Office for National Statistics (ONS) said.\n",
      "\n",
      "[6.13%] Clothing retailers and non-specialist stores were the worst hit with only internet retailers showing any significant growth, according to the ONS.\n",
      "\n",
      "\n",
      "=================================\n",
      "\n",
      "\n",
      "\n",
      "Full Text\n",
      "\n",
      "\n",
      "UK retail sales fell in December, failing to meet expectations and making it by some counts the worst Christmas since 1981.\n",
      "\n",
      "Retail sales dropped by 1% on the month in December, after a 0.6% rise in November, the Office for National Statistics (ONS) said. The ONS revised the annual 2004 rate of growth down from the 5.9% estimated in November to 3.2%. A number of retailers have already reported poor figures for December. Clothing retailers and non-specialist stores were the worst hit with only internet retailers showing any significant growth, according to the ONS.\n",
      "\n",
      "The last time retailers endured a tougher Christmas was 23 years previously, when sales plunged 1.7%.\n",
      "\n",
      "The ONS echoed an earlier caution from Bank of England governor Mervyn King not to read too much into the poor December figures. Some analysts put a positive gloss on the figures, pointing out that the non-seasonally-adjusted figures showed a performance comparable with 2003. The November-December jump last year was roughly comparable with recent averages, although some way below the serious booms seen in the 1990s. And figures for retail volume outperformed measures of actual spending, an indication that consumers are looking for bargains, and retailers are cutting their prices.\n",
      "\n",
      "However, reports from some High Street retailers highlight the weakness of the sector. Morrisons, Woolworths, House of Fraser, Marks & Spencer and Big Food all said that the festive period was disappointing.\n",
      "\n",
      "And a British Retail Consortium survey found that Christmas 2004 was the worst for 10 years. Yet, other retailers - including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that festive sales were well up on last year. Investec chief economist Philip Shaw said he did not expect the poor retail figures to have any immediate effect on interest rates. \"The retail sales figures are very weak, but as Bank of England governor Mervyn King indicated last night, you don't really get an accurate impression of Christmas trading until about Easter,\" said Mr Shaw. \"Our view is the Bank of England will keep its powder dry and wait to see the big picture.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Text Summary:\")\n",
    "for i in range(n):\n",
    "    print(f\"\\n[{sentence_score[idx_sort[i]]*100:.2f}%] {top_n_sentences[i]}\")\n",
    "\n",
    "print(\"\\n\\n=================================\\n\\n\")\n",
    "print(\"\\nFull Text\\n\")\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fee3813",
   "metadata": {
    "papermill": {
     "duration": 0.013095,
     "end_time": "2024-07-15T18:05:06.121194",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.108099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lets create a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc10e0f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:06.151007Z",
     "iopub.status.busy": "2024-07-15T18:05:06.150587Z",
     "iopub.status.idle": "2024-07-15T18:05:06.167734Z",
     "shell.execute_reply": "2024-07-15T18:05:06.166390Z"
    },
    "papermill": {
     "duration": 0.035433,
     "end_time": "2024-07-15T18:05:06.170580",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.135147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(document):\n",
    "    \n",
    "    #Remove the title\n",
    "    corpus = document.iloc[0].split(\"\\n\",1)[1]\n",
    "    \n",
    "    #Divide the text into sentences\n",
    "    docs = nltk.sent_tokenize(corpus)\n",
    "    \n",
    "    #Lemmatize the docs\n",
    "    docs_lemma = [lemmatize_text(doc) for doc in docs]\n",
    "\n",
    "    \n",
    "    #Compute Tf-Idf Matrix\n",
    "    tf_docs = TfidfVectorizer(decode_error='ignore', stop_words = 'english', norm = 'l1').fit_transform(docs_lemma)\n",
    "    N, V = tf_docs.shape\n",
    "    \n",
    "    #Computing the Markov-Matrix - M x M -> M = number of sentences\n",
    "    markov_matrix = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "\n",
    "        for j in range(N):\n",
    "\n",
    "            markov_matrix[i,j] = cosine_similarity(tf_docs[i,:], tf_docs[j,:])\n",
    "\n",
    "        #Normalize the row:\n",
    "        markov_matrix[i,:] = markov_matrix[i,:]/(markov_matrix[i,:].sum())\n",
    "        \n",
    "        \n",
    "    # Smoothing the matrix\n",
    "    lambda_smooth = 0.1\n",
    "    U = np.ones((N,N))*1/N\n",
    "\n",
    "    markov_matrix = markov_matrix*(1-lambda_smooth) + lambda_smooth*U\n",
    "    \n",
    "    \n",
    "    #Ensuring that is still normalized\n",
    "    norm_criteria = ((markov_matrix.sum(axis = 0) - 1).sum())\n",
    "\n",
    "    #Ensuring that all values > 0\n",
    "    norm_positive = ((markov_matrix[markov_matrix<=0].sum()))\n",
    "    \n",
    "    if norm_criteria>1e-5 or norm_positive>1e-5:\n",
    "        print(\"Conditions of the Matrix are NOT met\")\n",
    "        \n",
    "    #Computing eigenvector of markov_matrix\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(markov_matrix.T)\n",
    "    \n",
    "    \n",
    "    idx = find_eigenvectors(eigenvalues, 1)\n",
    "    p_inf = eigenvectors[:,idx]  #Limit distribution\n",
    "    sentence_score = p_inf/p_inf.sum() #Score\n",
    "    \n",
    "    \n",
    "    n = 5\n",
    "    idx_sort = np.argsort(-sentence_score)\n",
    "    top_n_sentences = [docs_lemma[idx] for idx in idx_sort[:n]]\n",
    "    \n",
    "    txt_title = document.iloc[0].split('\\n',1)[0]\n",
    "    print(f\"Text Title: {txt_title}\")\n",
    "    \n",
    "    print(\"\\nText Summary:\")\n",
    "    for i in range(n):\n",
    "        print(f\"\\n[{sentence_score[idx_sort[i]]*100:.2f}%] {top_n_sentences[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a0ede3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:06.200827Z",
     "iopub.status.busy": "2024-07-15T18:05:06.199562Z",
     "iopub.status.idle": "2024-07-15T18:05:06.387523Z",
     "shell.execute_reply": "2024-07-15T18:05:06.385987Z"
    },
    "papermill": {
     "duration": 0.206603,
     "end_time": "2024-07-15T18:05:06.390533",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.183930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Title: Goodrem wins top female MTV prize\n",
      "\n",
      "Text Summary:\n",
      "\n",
      "[11.59%] Goodrem , Green Day and the Black Eyed Peas take home two award each .\n",
      "\n",
      "[10.57%] Other winner include Green Day , vote best group , and the Black Eyed Peas .\n",
      "\n",
      "[10.29%] As well a best female , Goodrem also take home the Pepsi Viewers Choice Award , whilst Green Day bag the prize for best rock video for American Idiot .\n",
      "\n",
      "[10.01%] The Black Eyed Peas win award for best R 'n ' B video and sexy video , both for Hey Mama .\n",
      "\n",
      "[9.71%] Local singer and songwriter Missy Higgins take the title of breakthrough artist of the year , with Australian Idol winner Guy Sebastian take the honour for best pop video .\n"
     ]
    }
   ],
   "source": [
    "doc = df[df.labels == 'entertainment']['text'].sample(random_state=123)\n",
    "summarize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f947a62e",
   "metadata": {
    "papermill": {
     "duration": 0.013098,
     "end_time": "2024-07-15T18:05:06.417097",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.403999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TextRank - Using python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "059f94b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:06.445932Z",
     "iopub.status.busy": "2024-07-15T18:05:06.445481Z",
     "iopub.status.idle": "2024-07-15T18:05:28.245448Z",
     "shell.execute_reply": "2024-07-15T18:05:28.243839Z"
    },
    "papermill": {
     "duration": 21.81793,
     "end_time": "2024-07-15T18:05:28.248596",
     "exception": false,
     "start_time": "2024-07-15T18:05:06.430666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\r\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\r\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from sumy) (0.6.2)\r\n",
      "Collecting breadability>=0.1.20 (from sumy)\r\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from sumy) (2.32.3)\r\n",
      "Collecting pycountry>=18.2.23 (from sumy)\r\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: nltk>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from sumy) (3.2.4)\r\n",
      "Collecting chardet (from breadability>=0.1.20->sumy)\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: lxml>=2.0 in /opt/conda/lib/python3.10/site-packages (from breadability>=0.1.20->sumy) (5.2.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk>=3.0.2->sumy) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.7.0->sumy) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.7.0->sumy) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.7.0->sumy) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.7.0->sumy) (2024.2.2)\r\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: breadability\r\n",
      "  Building wheel for breadability (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21691 sha256=192d4ee030bd54f037937cf6eae1c02cbcb356824fd85d1d04782332e681ae32\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\r\n",
      "Successfully built breadability\r\n",
      "Installing collected packages: pycountry, chardet, breadability, sumy\r\n",
      "Successfully installed breadability-0.1.20 chardet-5.2.0 pycountry-24.6.1 sumy-0.11.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52fdaa84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:28.282035Z",
     "iopub.status.busy": "2024-07-15T18:05:28.281577Z",
     "iopub.status.idle": "2024-07-15T18:05:28.449279Z",
     "shell.execute_reply": "2024-07-15T18:05:28.448084Z"
    },
    "papermill": {
     "duration": 0.188202,
     "end_time": "2024-07-15T18:05:28.452280",
     "exception": false,
     "start_time": "2024-07-15T18:05:28.264078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sumy libraries do the job!\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer  #Latent Semantic Analysis\n",
    "from sumy.parsers.plaintext import PlaintextParser #Parse the text -> Create the 'vector' from the text that will be used\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64379f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:28.484899Z",
     "iopub.status.busy": "2024-07-15T18:05:28.484469Z",
     "iopub.status.idle": "2024-07-15T18:05:28.744234Z",
     "shell.execute_reply": "2024-07-15T18:05:28.742933Z"
    },
    "papermill": {
     "duration": 0.279319,
     "end_time": "2024-07-15T18:05:28.747138",
     "exception": false,
     "start_time": "2024-07-15T18:05:28.467819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer = TextRankSummarizer()\n",
    "\n",
    "#We need to pass the text, and the tokenizer to create the parser object\n",
    "parser = PlaintextParser.from_string(\n",
    "    doc.iloc[0].split(\"\\n\", 1)[1],\n",
    "    Tokenizer(\"english\"))\n",
    "\n",
    "#sentences_count = number of outputs\n",
    "summary = summarizer(parser.document, sentences_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "530b6491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:28.780045Z",
     "iopub.status.busy": "2024-07-15T18:05:28.779603Z",
     "iopub.status.idle": "2024-07-15T18:05:28.787290Z",
     "shell.execute_reply": "2024-07-15T18:05:28.786238Z"
    },
    "papermill": {
     "duration": 0.027071,
     "end_time": "2024-07-15T18:05:28.789870",
     "exception": false,
     "start_time": "2024-07-15T18:05:28.762799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: The 21-year-old singer won the award for best female artist, with Australian Idol runner-up Shannon Noll taking the title of best male at the ceremony.>,\n",
       " <Sentence: As well as best female, Goodrem also took home the Pepsi Viewers Choice Award, whilst Green Day bagged the prize for best rock video for American Idiot.>,\n",
       " <Sentence: The Black Eyed Peas won awards for best R 'n' B video and sexiest video, both for Hey Mama.>,\n",
       " <Sentence: Local singer and songwriter Missy Higgins took the title of breakthrough artist of the year, with Australian Idol winner Guy Sebastian taking the honours for best pop video.>,\n",
       " <Sentence: The ceremony was held at the Luna Park fairground in Sydney Harbour and was hosted by the Osbourne family.>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7cf02a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:28.823626Z",
     "iopub.status.busy": "2024-07-15T18:05:28.823155Z",
     "iopub.status.idle": "2024-07-15T18:05:28.829407Z",
     "shell.execute_reply": "2024-07-15T18:05:28.828225Z"
    },
    "papermill": {
     "duration": 0.026165,
     "end_time": "2024-07-15T18:05:28.832007",
     "exception": false,
     "start_time": "2024-07-15T18:05:28.805842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 21-year-old singer won the award for best female artist, with Australian Idol runner-up Shannon Noll taking the title of best male at the ceremony.\n",
      "As well as best female, Goodrem also took home the Pepsi Viewers Choice Award, whilst Green Day bagged the prize for best rock video for American Idiot.\n",
      "The Black Eyed Peas won awards for best R 'n' B video and sexiest video, both for Hey Mama.\n",
      "Local singer and songwriter Missy Higgins took the title of breakthrough artist of the year, with Australian Idol winner Guy Sebastian taking the honours for best pop video.\n",
      "The ceremony was held at the Luna Park fairground in Sydney Harbour and was hosted by the Osbourne family.\n"
     ]
    }
   ],
   "source": [
    "for s in summary:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c619916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T18:05:28.866976Z",
     "iopub.status.busy": "2024-07-15T18:05:28.866062Z",
     "iopub.status.idle": "2024-07-15T18:05:28.879061Z",
     "shell.execute_reply": "2024-07-15T18:05:28.877314Z"
    },
    "papermill": {
     "duration": 0.034434,
     "end_time": "2024-07-15T18:05:28.882141",
     "exception": false,
     "start_time": "2024-07-15T18:05:28.847707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodrem, known in both Britain and Australia for her role as Nina Tucker in TV soap Neighbours, also performed a duet with boyfriend Brian McFadden.\n",
      "Other winners included Green Day, voted best group, and the Black Eyed Peas.\n",
      "Goodrem, Green Day and the Black Eyed Peas took home two awards each.\n",
      "As well as best female, Goodrem also took home the Pepsi Viewers Choice Award, whilst Green Day bagged the prize for best rock video for American Idiot.\n",
      "Artists including Carmen Electra, Missy Higgins, Kelly Osbourne, Green Day, Ja Rule and Natalie Imbruglia gave live performances at the event.\n"
     ]
    }
   ],
   "source": [
    "#Using LSA\n",
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, sentences_count=5)\n",
    "for s in summary:\n",
    "  print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e98e5",
   "metadata": {
    "papermill": {
     "duration": 0.016266,
     "end_time": "2024-07-15T18:05:28.914262",
     "exception": false,
     "start_time": "2024-07-15T18:05:28.897996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5180651,
     "sourceId": 8649066,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.132107,
   "end_time": "2024-07-15T18:05:30.056105",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-15T18:04:54.923998",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
